{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "peak rank with 2000-2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iil-z5_1dSNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227e59b5-d02f-4b62-c654-feccfe08c643"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools import eval_measures\n",
        "from sklearn.metrics import r2_score\n",
        "# from util import all_variable_names_in_df, train_test_split, RANDOM_SEED\n",
        "from google.colab import files\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiIynLYSdivh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ba977f-4cb4-42af-9489-3021e7414fee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# I copied the data to my main drive and named it \"Copy_of_train.csv\"\n",
        "path = \"/content/gdrive/My Drive/Copy of pop_songs_data _2000s_on.csv\"\n",
        "#path = \"/content/gdrive/My Drive/SMAK Data Science/train.csv\"\n",
        "with open(path, 'rb') as f:\n",
        "  df = pd.read_csv(f)\n",
        "print(\"Finished reading data!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Finished reading data!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIbl9mMN3yKH"
      },
      "source": [
        "RANDOM_SEED = 0\n",
        "\n",
        "def train_test_split(df, train_pct=0.8):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - df: Pandas DataFrame\n",
        "        - train_pct: optional, float\n",
        "    Output:\n",
        "        - train dataframe: Pandas DataFrame\n",
        "        - test dataframe: Pandas DataFrame\n",
        "    \"\"\"\n",
        "    random.seed(RANDOM_SEED)\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    msk = np.random.rand(len(df)) < train_pct\n",
        "    return df[msk], df[~msk]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_c7wZPP3-9d"
      },
      "source": [
        "train_data, test_data = train_test_split(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd6RXJorTTNj",
        "outputId": "3b02dc15-d19a-4af9-c673-5c417098f8e6"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.tools import eval_measures\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "IND_VAR_NAMES = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence', 'key']\n",
        "DEP_VAR_NAME = \"peak_rank\"\n",
        "\n",
        "X_train = train_data[IND_VAR_NAMES]\n",
        "X_test = test_data[IND_VAR_NAMES]\n",
        "\n",
        "y_train = train_data[DEP_VAR_NAME]\n",
        "y_test = test_data[DEP_VAR_NAME]\n",
        "\n",
        "x_train_with_constant = sm.add_constant(X_train)\n",
        "mod = sm.OLS(y_train, x_train_with_constant)\n",
        "result = mod.fit()\n",
        "\n",
        "mse_train = eval_measures.mse(y_train, result.predict(x_train_with_constant))\n",
        "\n",
        "x_test_with_constant = sm.add_constant(X_test)\n",
        "mse_test = eval_measures.mse(y_test, result.predict(x_test_with_constant))\n",
        "\n",
        "# TODO: Calculate the *test* R-squared value (using sklearn's r2_score function)\n",
        "rsquared_val = r2_score(y_test, result.predict(x_test_with_constant))\n",
        "\n",
        "# TODO: Print out the summary to see more information as needed\n",
        "print(result.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              peak_rank   R-squared:                       0.031\n",
            "Model:                            OLS   Adj. R-squared:                  0.029\n",
            "Method:                 Least Squares   F-statistic:                     19.93\n",
            "Date:                Tue, 27 Jul 2021   Prob (F-statistic):           9.74e-37\n",
            "Time:                        14:10:25   Log-Likelihood:                -29930.\n",
            "No. Observations:                6234   AIC:                         5.988e+04\n",
            "Df Residuals:                    6223   BIC:                         5.996e+04\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "const               59.1904      5.140     11.515      0.000      49.113      69.267\n",
            "acousticness         9.1158      2.176      4.189      0.000       4.850      13.382\n",
            "danceability       -14.3924      2.977     -4.834      0.000     -20.228      -8.556\n",
            "duration_ms       -7.35e-05   8.57e-06     -8.579      0.000   -9.03e-05   -5.67e-05\n",
            "energy              14.8758      3.742      3.975      0.000       7.539      22.212\n",
            "instrumentalness    17.8977      6.005      2.980      0.003       6.125      29.671\n",
            "loudness            -0.6876      0.245     -2.805      0.005      -1.168      -0.207\n",
            "speechiness         17.9004      3.487      5.134      0.000      11.065      24.736\n",
            "tempo                0.0194      0.013      1.486      0.137      -0.006       0.045\n",
            "valence             -9.8046      2.061     -4.757      0.000     -13.845      -5.764\n",
            "key                 -0.0992      0.104     -0.956      0.339      -0.303       0.104\n",
            "==============================================================================\n",
            "Omnibus:                     3908.615   Durbin-Watson:                   0.090\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.993\n",
            "Skew:                           0.055   Prob(JB):                     1.35e-77\n",
            "Kurtosis:                       1.838   Cond. No.                     3.91e+06\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 3.91e+06. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQwF-dsxhIXp"
      },
      "source": [
        "def all_variable_names_in_df(variable_names, df):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - variable_names: list of string, of all the variable\n",
        "                        names to check whether they're in the df or nah\n",
        "        - df: Pandas DataFrame\n",
        "\n",
        "    Output:\n",
        "        - boolean: True if all the variable names are the columns of df,\n",
        "                    False if not\n",
        "    \"\"\"\n",
        "    columns = set(df.columns)\n",
        "    for variable_name in variable_names:\n",
        "        if variable_name not in columns:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deDhWVltdJKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305337fe-5b0b-4eb9-aecd-938fd1612a6a"
      },
      "source": [
        "def regression(train_df, test_df, ind_var_names: list, dep_var_name: str):\n",
        "    \"\"\"\n",
        "    Implement Linear Regression using StatsModel.\n",
        "\n",
        "    inputs:\n",
        "        - train_df: a Pandas DataFrame, containing all the training samples\n",
        "        - test_df: a Pandas DataFrame, containing all the testing samples\n",
        "        - ind_var_names: a list of strings of independent variable columns\n",
        "                        that we want to include in the model\n",
        "        - dep_var_name: the name of the dependent variable of our model\n",
        "    \n",
        "\n",
        "    outpus:\n",
        "        - mse_train: the mean-squared error of the model (trained on the training\n",
        "                    data), evaluated on the training dataset\n",
        "        - mse_test: the mean-squared error of the model (trained on the training\n",
        "                    data), evaluated on the testing dataset\n",
        "        - rsquared_val: the r-squared value of the model (trained on the training\n",
        "                    data), evaluated on the testing dataset\n",
        "    \"\"\"\n",
        "    ## Stencil: Error check whether the input that you provided to the function is correct or not\n",
        "    # Do not modify\n",
        "    for df in [train_df, test_df]:\n",
        "        assert all_variable_names_in_df(ind_var_names + [dep_var_name], df)\n",
        "\n",
        "    # TODO: Construct X_train, X_test, y_train, y_test from train_df and test_df, where\n",
        "    # X_train is a numpy array of all the independent variable instances from train_df,\n",
        "    # y_train is a numpy array of all the dependent variable instances from train_df,\n",
        "    # and the same applies to X_test and y_test from test_df.\n",
        "    # Hint: Look up (1) how to select a Pandas DataFrame B with a subset of columns from a given DataFrame A,\n",
        "    #           and (2) how to use Pandas .to_numpy() function.\n",
        "    X_train = train_df[ind_var_names].to_numpy()\n",
        "    X_test = test_df[ind_var_names].to_numpy()\n",
        "    y_train = train_df[dep_var_name].to_numpy()\n",
        "    y_test = test_df[dep_var_name].to_numpy()\n",
        "\n",
        "    # TODO: Using statsmodel, fit a linear regression model to the training dataset\n",
        "    # You may checkout statsmodel's documentation here: https://www.statsmodels.org/stable/regression.html\n",
        "    x_train_with_constant = sm.add_constant(X_train) ##TODO: Why???\n",
        "    mod = sm.OLS(y_train, x_train_with_constant)\n",
        "    result = mod.fit()\n",
        "\n",
        "    # TODO: Using statsmodel's eval_measures MSE calculation function,\n",
        "    # calculate the Mean-squared Error of the model above (on the training dataset)\n",
        "    mse_train = eval_measures.mse(y_train, result.predict(x_train_with_constant)) \n",
        "\n",
        "    # TODO: Similarly, calculate the Mean-squared Error of the model above (on the testing dataset)\n",
        "    x_test_with_constant = sm.add_constant(X_test) ##TODO: Why???\n",
        "    mse_test = eval_measures.mse(y_test, result.predict(x_test_with_constant)) # would the axis be 1?\n",
        "    \n",
        "    # TODO: Calculate the *test* R-squared value (using sklearn's r2_score function)\n",
        "    rsquared_val = r2_score(y_test, result.predict(x_test_with_constant))\n",
        "\n",
        "    # TODO: Print out the summary to see more information as needed\n",
        "    print(result.summary())\n",
        "\n",
        "    # TODO: Replace these values with whatever you found!\n",
        "    mse_train, mse_test, rsquared_val = mse_train, mse_test, rsquared_val\n",
        "    \n",
        "    # And return them! :)\n",
        "    return mse_train, mse_test, rsquared_val\n",
        "    \n",
        "\n",
        "def main():\n",
        "    # TODO: Load the data from the bike-sharing.csv file into a Pandas DataFrame. Do not change\n",
        "    # the variable name /data/\n",
        "    # Hint: Look at the Pandas' read_csv function\n",
        "    ###data = pd.read_csv(\"../data/bike-sharing.csv\")\n",
        "   \n",
        "\n",
        "    \n",
        "    \n",
        "    # TODO: Uncomment this to print out the column names of data to know what features there are \n",
        "    # in the dataset\n",
        "    #print(\"Columns: \", data.columns)\n",
        "\n",
        "    # TODO: Modify the list IND_VAR_NAMES to select the independent variables you want to perform\n",
        "    # a linear regression on\n",
        "    IND_VAR_NAMES = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence', 'key']\n",
        "    #IND_VAR_NAMES = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'loudness', 'speechiness']\n",
        "    #IND_VAR_NAMES = ['speechiness']\n",
        "    \n",
        "\n",
        "    # Select the dependent variable name DEP_VAR_NAME (default is \"cnt\")\n",
        "    DEP_VAR_NAME = \"peak_rank\"\n",
        "\n",
        "    # TODO: Using the imported train_test_split function (from util.py), create the train_df and\n",
        "    # test_df that will be passed into regression. $$ASK HERE!!\n",
        "    ####train_data, test_data = train_test_split(data)\n",
        "    #x_train, x_test, y_train, y_test = train_test_split(x, y) ???\n",
        "\n",
        "    # TODO: Call regression and perform other calculations as you deem necessary to answer the\n",
        "    # questions posed for this section.\n",
        "    regression(train_data, test_data, IND_VAR_NAMES, DEP_VAR_NAME)\n",
        "\n",
        "############ DON'T MODIFY BELOW THIS LINE ############\n",
        "main()\n",
        "# if __name__ == \"__main__\":\n",
        "#     np.random.seed(RANDOM_SEED)\n",
        "#     random.seed(RANDOM_SEED)\n",
        "#     main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.031\n",
            "Model:                            OLS   Adj. R-squared:                  0.029\n",
            "Method:                 Least Squares   F-statistic:                     19.93\n",
            "Date:                Tue, 27 Jul 2021   Prob (F-statistic):           9.74e-37\n",
            "Time:                        14:11:43   Log-Likelihood:                -29930.\n",
            "No. Observations:                6234   AIC:                         5.988e+04\n",
            "Df Residuals:                    6223   BIC:                         5.996e+04\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         59.1904      5.140     11.515      0.000      49.113      69.267\n",
            "x1             9.1158      2.176      4.189      0.000       4.850      13.382\n",
            "x2           -14.3924      2.977     -4.834      0.000     -20.228      -8.556\n",
            "x3          -7.35e-05   8.57e-06     -8.579      0.000   -9.03e-05   -5.67e-05\n",
            "x4            14.8758      3.742      3.975      0.000       7.539      22.212\n",
            "x5            17.8977      6.005      2.980      0.003       6.125      29.671\n",
            "x6            -0.6876      0.245     -2.805      0.005      -1.168      -0.207\n",
            "x7            17.9004      3.487      5.134      0.000      11.065      24.736\n",
            "x8             0.0194      0.013      1.486      0.137      -0.006       0.045\n",
            "x9            -9.8046      2.061     -4.757      0.000     -13.845      -5.764\n",
            "x10           -0.0992      0.104     -0.956      0.339      -0.303       0.104\n",
            "==============================================================================\n",
            "Omnibus:                     3908.615   Durbin-Watson:                   0.090\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.993\n",
            "Skew:                           0.055   Prob(JB):                     1.35e-77\n",
            "Kurtosis:                       1.838   Cond. No.                     3.91e+06\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 3.91e+06. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKgXfhUHgzX5"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "\n",
        "cols2 = ['date', 'weeks_on_board', 'speechiness']\n",
        "\n",
        "\n",
        "def make_all_data_scatter_plot2(metric):\n",
        "  scatter_plot = sns.scatterplot()\n",
        "\n",
        "def make_scatter_plot():\n",
        "  scatter_plot = sns.catplot(data=train_data.loc[train_data[\"date\"] >= 1990],\n",
        "  # scatter_plot = sns.catplot(data=train_data,\n",
        "            kind=\"strip\",\n",
        "            x=\"speechiness\",\n",
        "            y= \"peak_rank\",\n",
        "            height=5,\n",
        "            aspect=6,\n",
        "            hue='date'\n",
        "            ).set(\n",
        "                title= 'energy_vs_peak_rank'\n",
        "            )\n",
        "  return scatter_plot\n",
        "\n",
        "make_scatter_plot()\n",
        "\n",
        "# def make_all_scatterplots2():\n",
        "#   for col in cols2[1:]:\n",
        "#     plot = make_scatter_plots2(col)\n",
        "#     plot.savefig(col + '_output_scatter.png')\n",
        "#     files.download(col + '_output_scatter.png')\n",
        "#   print('Done making scatterplots')\n",
        "\n",
        "# make_all_scatterplots2()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}